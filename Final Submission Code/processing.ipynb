{"cells":[{"cell_type":"markdown","metadata":{"id":"YE6Zc2UyKwaP"},"source":["# Data Processing"]},{"cell_type":"markdown","metadata":{"id":"t2YRBEELKwaQ"},"source":["This notebook will extract chroma, mfcc, and spectral features from each audio file and combine them into a large data matrix which we will use in our analyses.\n","\n","Importantly, we segment each 30-second audio clip into 20 clips each 1.5 seconds long. In doing this, we hope to minimize the variation in each audio clip, so that the extracted features closely match the genre that it is labelled by."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6CxuvuFOKwaR"},"outputs":[],"source":["import os\n","import pandas as pd\n","import librosa\n","import numpy as np\n","from scipy.spatial.distance import euclidean\n","from collections import Counter\n","import soundfile as sf\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.cluster import KMeans\n","from scipy.stats import mode\n","import csv\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BpO2YiKAKwaR"},"outputs":[],"source":["train_filenames = sorted(os.listdir(\"Dataset/train\"))\n","train_filenames = [filename for filename in train_filenames if filename != \".DS_Store\"]\n","test_filenames = sorted(os.listdir(\"Dataset/test\"))\n","test_filenames = [filename for filename in test_filenames if filename != \".DS_Store\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3aVnxKlKwaS"},"outputs":[],"source":["n_mfcc = 35\n","num_segments = 20"]},{"cell_type":"markdown","metadata":{"id":"-pRsXwk1KwaS"},"source":["## Extract features from training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pyhcY_TqKwaS"},"outputs":[],"source":["train_labels = pd.read_csv(\"Dataset/train.csv\")\n","genres = train_labels['Genre'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wpE-QIYKwaS","outputId":"f0f212fb-cf34-4c96-e720-faddaea6bba1"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=517\n","  warnings.warn(\n","/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=518\n","  warnings.warn(\n","/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=521\n","  warnings.warn(\n","/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=522\n","  warnings.warn(\n","/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=523\n","  warnings.warn(\n","/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=516\n","  warnings.warn(\n","/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=524\n","  warnings.warn(\n","/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=519\n","  warnings.warn(\n","/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=528\n","  warnings.warn(\n","/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=520\n","  warnings.warn(\n","/Users/lance/.pyenv/versions/3.9.18/lib/python3.9/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=526\n","  warnings.warn(\n"]}],"source":["train_features = []\n","train_labels = []\n","\n","for i in range(len(train_filenames)):\n","    filename = train_filenames[i]\n","    genre = genres[i]\n","    file_path = os.path.join('Dataset/train', filename)\n","    y, sr = librosa.load(file_path)\n","    segments = np.array_split(y, num_segments)\n","    for segment in segments:\n","        all_features = []\n","        chroma_features = librosa.feature.chroma_cqt(y=segment, sr=sr).mean(axis=1)\n","        mfcc_features = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=n_mfcc).mean(axis=1)\n","        contrast_features = librosa.feature.spectral_contrast(y=segment, sr=sr, n_fft=512).mean(axis=1)\n","        flatness_features = librosa.feature.spectral_flatness(y=segment, n_fft=512).mean(axis=1)\n","\n","        all_features.extend(chroma_features)\n","        all_features.extend(mfcc_features)\n","        all_features.extend(contrast_features)\n","        all_features.extend(flatness_features)\n","        train_features.append(all_features)\n","        train_labels.append(genre)\n","\n","train_features = np.matrix(train_features)"]},{"cell_type":"markdown","metadata":{"id":"lLVXuwzkKwaT"},"source":["## Extract features from testing set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZvpNqJv5KwaT"},"outputs":[],"source":["test_features = []\n","\n","for i in range(len(test_filenames)):\n","    filename = test_filenames[i]\n","    file_path = os.path.join('Dataset/test', filename)\n","    y, sr = librosa.load(file_path)\n","    segments = np.array_split(y, num_segments)\n","    for segment in segments:\n","        all_features = []\n","        chroma_features = librosa.feature.chroma_cqt(y=segment, sr=sr).mean(axis=1)\n","        mfcc_features = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=n_mfcc).mean(axis=1)\n","        contrast_features = librosa.feature.spectral_contrast(y=segment, sr=sr, n_fft=512).mean(axis=1)\n","        flatness_features = librosa.feature.spectral_flatness(y=segment, n_fft=512).mean(axis=1)\n","\n","        all_features.extend(chroma_features)\n","        all_features.extend(mfcc_features)\n","        all_features.extend(contrast_features)\n","        all_features.extend(flatness_features)\n","        test_features.append(all_features)\n","\n","test_features = np.matrix(test_features)"]},{"cell_type":"markdown","metadata":{"id":"oI_uxfAvKwaT"},"source":["## Normalize data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xu2y7xpkKwaT"},"outputs":[],"source":["scaler = StandardScaler()\n","\n","train_features = scaler.fit_transform(np.asarray(train_features))\n","test_features = scaler.transform(np.asarray(test_features))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOruttTVKwaU"},"outputs":[],"source":["if not os.path.isdir(\"Processed(7)\"): os.mkdir(\"Processed(7)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZcxTjvHsKwaU"},"outputs":[],"source":["np.save(\"Processed(7)/train_features\", train_features)\n","np.save(\"Processed(7)/test_features\", test_features)\n","np.save(\"Processed(7)/train_labels\", train_labels)\n","np.save(\"Processed(7)/unshortened_train_labels\", genres)"]},{"cell_type":"markdown","metadata":{"id":"329I8447KwaU"},"source":["## Extra: make a submission folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vk3GDxG7KwaU"},"outputs":[],"source":["if not os.path.isdir(\"Submissions\"): os.mkdir(\"Submissions\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}